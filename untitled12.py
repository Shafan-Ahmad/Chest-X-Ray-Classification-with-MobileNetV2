# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CXdfCSMHoHxLEa4mA87bDFfxOjAC8C9p
"""

from google.colab import drive
drive.mount('/content/saAdrive')

pip install torch torchvision

import os
import torch
import torchvision
from torchvision import transforms, datasets
from torch.utils.data import DataLoader, Subset
from torch import nn, optim
from torch.cuda.amp import autocast, GradScaler
import matplotlib.pyplot as plt
import random

# Check device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Paths to dataset
dataset_path = "/content/saAdrive/MyDrive/AI /MACHINE LEARNING/chest_xray"  # Replace with your dataset path
train_dir = os.path.join(dataset_path, 'train')
val_dir = os.path.join(dataset_path, 'val')
test_dir = os.path.join(dataset_path, 'test')


# Define transformations (with lower resolution)
transform = transforms.Compose([
    transforms.Resize((128, 128)),  # Lower resolution for faster processing
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]
])

# Load datasets
train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)
val_dataset = datasets.ImageFolder(root=val_dir, transform=transform)
test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)

# Reduce dataset size
def get_subset(dataset, num_samples_per_class):
    indices = []
    class_to_indices = {cls: [] for cls in range(len(dataset.classes))}

    for idx, (_, label) in enumerate(dataset):
        class_to_indices[label].append(idx)

    for cls, cls_indices in class_to_indices.items():
        selected_indices = random.sample(cls_indices, min(num_samples_per_class, len(cls_indices)))
        indices.extend(selected_indices)

    return Subset(dataset, indices)

# Limit samples per class (e.g., 10 per class)
train_dataset = get_subset(train_dataset, 10)
val_dataset = get_subset(val_dataset, 10)
test_dataset = get_subset(test_dataset, 10)

# Create data loaders with larger batch size
batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# Show a few images with labels
def show_samples(dataset, classes):
    plt.figure(figsize=(10, 10))
    for i in range(9):
        img, label = dataset[i]
        img = img.permute(1, 2, 0).numpy()
        plt.subplot(3, 3, i + 1)
        plt.imshow((img * 0.5) + 0.5)  # Denormalize
        plt.title(f"Label: {classes[label]}")
        plt.axis("off")
    plt.tight_layout()
    plt.show()

classes = train_dataset.dataset.classes
show_samples(train_dataset, classes)

# Define the CNN model (using MobileNetV2 for speed)
model = torchvision.models.mobilenet_v2(pretrained=True)
model.classifier[1] = nn.Linear(model.last_channel, 1)  # Binary classification
model = model.to(device)

# Define loss and optimizer
criterion = nn.BCEWithLogitsLoss()  # Combines Sigmoid + Binary Cross Entropy
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Mixed precision scaler
scaler = GradScaler()

# Training loop with mixed precision
def train_model_mixed_precision(model, train_loader, val_loader, criterion, optimizer, epochs=2):
    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device, dtype=torch.float32).unsqueeze(1)
            optimizer.zero_grad()

            with autocast():  # Mixed precision
                outputs = model(images)
                loss = criterion(outputs, labels)

            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            running_loss += loss.item()

        print(f"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}")

        # Validation
        model.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device, dtype=torch.float32).unsqueeze(1)
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                predictions = torch.sigmoid(outputs) > 0.5
                correct += (predictions == labels).sum().item()
                total += labels.size(0)

        print(f"Validation Loss: {val_loss / len(val_loader):.4f}, Accuracy: {correct / total:.4f}")

# Train the model
train_model_mixed_precision(model, train_loader, val_loader, criterion, optimizer, epochs=2)

# Test the model
def test_model(model, test_loader):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device, dtype=torch.float32).unsqueeze(1)
            outputs = model(images)
            predictions = torch.sigmoid(outputs) > 0.5
            correct += (predictions == labels).sum().item()
            total += labels.size(0)

    print(f"Test Accuracy: {correct / total:.4f}")

test_model(model, test_loader)

